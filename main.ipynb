{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9281f9a",
   "metadata": {},
   "source": [
    "### 1. Installing the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Tensorflow gpu\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of the Tensorflow installation\n",
    "!python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Opencv library\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb32dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Coco api\n",
    "!pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feffe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating different folders for data support\n",
    "\n",
    "if not os.path.exists('Tensorflow'):\n",
    "    !mkdir Tensorflow\\models\n",
    "    !mkdir Tensorflow\\labelimg\n",
    "    !mkdir Tensorflow\\workspace \n",
    "    !mkdir Tensorflow\\workspace\\annotations\n",
    "    !mkdir Tensorflow\\workspace\\images\n",
    "    !mkdir Tensorflow\\workspace\\models\n",
    "    !mkdir Tensorflow\\workspace\\pre-trained-models\n",
    "    !mkdir Tensorflow\\workspace\\images\\train\n",
    "    !mkdir Tensorflow\\workspace\\images\\test\n",
    "    !mkdir Tensorflow\\scripts\\preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1efc095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git cloning the entire Tensorflow object Detection repositories\n",
    "!cd Tensorflow/&& git clone https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d373a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to check the protobuf installation\n",
    "# Navigate in cmd to TensorFlow/models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=. # Run in command prompt\n",
    "\n",
    "# Or run directly here\n",
    "!cd Tensorflow/models/research/ && protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef406377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protobuf verifications\n",
    "# Navigate in cmd to  TensorFlow/models/research/\n",
    "# Run in command prompt \n",
    "for /f %i in ('dir /b object_detection\\protos\\*.proto') do protoc object_detection\\protos\\%i --python_out=.    \n",
    "\n",
    "# Or run directly here\n",
    "!cd Tensorflow/models/research/ && for /f %i in ('dir /b object_detection\\protos\\*.proto') do protoc object_detection\\protos\\%i --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the Object Detection API\n",
    "!cd Tensorflow/models/research && cp object_detection/packages/tf2/setup.py . && python -m pip install --use-feature=2020-resolver ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying the installation\n",
    "# From within TensorFlow/models/research/\n",
    "!cd TensorFlow/models/research/object_detection/builders/ && python model_builder_tf2_test.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aae30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pyqt5 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4320738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the GUI for Image Labelling to create xml file for each image\n",
    "!pip install labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e323e5",
   "metadata": {},
   "source": [
    "### 2. Collecting Images to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f657271",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['thumbsup', 'thumbsdown', 'palm', 'fist','ok']\n",
    "number_of_images = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_location = os.path.join('Tensorflow', 'workspace', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71633218",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    path = os.path.join(Images_location, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3533e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Dont run this cell unless you need to capture live images for train data set ***\n",
    "\n",
    "# Collecting images using webcam\n",
    "\n",
    "counter = 0\n",
    "for label in labels:\n",
    "    for image_no in range(number_of_images):\n",
    "        cam = cv2.VideoCapture(0)\n",
    "        cam.set(3, 640)\n",
    "        cam.set(4, 480)\n",
    "        cam.set(10, 100)\n",
    "        ret, frame = cam.read()\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "        img_location = os.path.join(Images_location, label, f\"{label}_{counter}.jpg\")\n",
    "        cv2.imwrite(img_location, frame)  # Saving the  image\n",
    "        print(f\"{label}_{counter}.jpg\")\n",
    "        counter += 1\n",
    "        time.sleep(5)\n",
    "        if cv2.waitKey(5) % 256 == 27:\n",
    "            print('Escape pressed. Closing the application')\n",
    "            break\n",
    "\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the GUI for image labelling\n",
    "labelimage_path = os.path.join('Tensorflow', 'labelimg')\n",
    "!cd {labelimage_path} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6007c52",
   "metadata": {},
   "source": [
    "Save the xml files of train and test images in their respective folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007fced",
   "metadata": {},
   "source": [
    "Split the total images in the ratio of 9:1 and paste into train and test folders "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ecfac",
   "metadata": {},
   "source": [
    "## 3. Creating Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe161cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'thumbsup', 'id':1}, {'name':'thumbsdown', 'id':2}, {'name':'palm', 'id':3}, {'name':'fist', 'id':4}, {'name':'ok', 'id':5}]\n",
    "label_map_name = 'label_map.pbtxt'\n",
    "label_path = os.path.join('Tensorflow','workspace','annotations',label_map_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(label_path, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc02d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_path = os.path.join('Tensorflow','scripts','preprocessing','generate_tfrecord.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the *.record file for test data and train data after mapping every image for its respective xml file\n",
    "!cd Tensorflow/scripts/ && python generate_tfrecord.py -x D:work/Tensorflow/workspace/images/train -l D:/work/Tensorflow/workspace/annotations/label_map.pbtxt -o D:/work/Tensorflow/workspace/annotations/train.record\n",
    "\n",
    "!cd Tensorflow/scripts/ && python generate_tfrecord.py -x D:work/Tensorflow/workspace/images/test -l D:/work/Tensorflow/workspace/annotations/label_map.pbtxt -o D:/work/Tensorflow/workspace/annotations/test.record\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f97567",
   "metadata": {},
   "source": [
    "## 4. Downloading the model from Tensorflow model garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086caeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46485f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6efa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Tensorflow/workspace/pre-trained-models/\n",
    "wget.download(model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!move ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8*.gz Tensorflow/workspace/pre-trained-models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e79e6d",
   "metadata": {},
   "source": [
    "Extract the tar file and paste the contents in the pre-trained-models folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating folder for OUR CUSTOM model\n",
    "\n",
    "\n",
    "!mkdir Tensorflow\\workspace\\models\\my_ssd_mobnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9add47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the 'pipeline.config' file from pre-trained-models folder to  'my_ssd_resnet50_v1_fpn' folder\n",
    "\n",
    "\n",
    "!copy Tensorflow\\workspace\\pre-trained-models\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\\pipeline.config Tensorflow\\workspace\\models\\my_ssd_mobnet\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c281c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipe line config path \n",
    "pipeline_path = os.path.join('Tensorflow','workspace','models', 'my_ssd_mobnet', 'pipeline.config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5974b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration_path = os.path(Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config)\n",
    "config = config_util.get_configs_from_pipeline_file(pipeline_path)  \n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc3f8a",
   "metadata": {},
   "source": [
    "### Open the pipeline.config file and make the following changes \n",
    "\n",
    "\n",
    "\n",
    "*** Under ssd ***\n",
    "\n",
    "* num_classes: 5              ##### Number of items to detect ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*** Under fine_tune_checkpoint ***\n",
    "\n",
    "* fine_tune_checkpoint: \"Tensorflow\\\\workspace\\\\pre-trained-models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-                                         8\\\\checkpoint\\\\ckpt-0\"                       #### Path to checkpoint of pre-trained model######\n",
    "\n",
    "* fine_tune_checkpoint_type: \"detection\" #####  Set this to \"detection\" since we want to be training the full detection model                                                    ######\n",
    "\n",
    "* fine_tune_checkpoint: \"Tensorflow\\\\workspace\\\\pre-trained-models\\\\ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-                   8\\\\checkpoint\\\\ckpt-0\"                                          ##### Path to checkpoint of pre-trained model######\n",
    "\n",
    "* num_steps: 50000                                ######  Based on your config  ###### i used 2000 and 2500\n",
    "\n",
    "* fine_tune_checkpoint_type: \"detection\"       #####  Set this to \"detection\" since we want to be training the full detection model                                                    ######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*** Under train_input_reader  ***\n",
    "\n",
    "* label_map_path: \"Tensorflow\\\\workspace\\\\annotations\\\\label_map.pbtxt\"         ##### Path to label map  #####\n",
    "    \n",
    "* input_path: \"Tensorflow\\\\workspace\\\\annotations\\\\train.record\"              ##### Path to training record file ####\n",
    "  \n",
    "* metrics_set: \"coco_detection_metrics\"                                         #### Since the model is coco based  ####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*** Under eval_input_reader ***\n",
    "\n",
    "* label_map_path: \"Tensorflow\\\\workspace\\\\annotations\\\\label_map.pbtxt\"         #### Path to label map file #####\n",
    "* input_path: \"Tensorflow\\\\workspace\\\\annotations\\\\test.record\"               ###### Path to test record file  #####\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runing config again to see if the changes we made is visible or not\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3eb0a",
   "metadata": {},
   "source": [
    "## 5. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdce61b",
   "metadata": {},
   "source": [
    " copy the TensorFlow/models/research/object_detection/model_main_tf2.py into workspace folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if your machine has GPU installed. Install CUDA and cuDNN for your respective TF version(kindly refer instructions)\n",
    "\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num of GPU:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67356a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on our data set\n",
    "# Run the command in cmd to see the progress\n",
    "# add '--num_train_steps=2500' value of your choice for the compuatation, else the model will run for 50000 steps\n",
    "\n",
    "\n",
    "python Tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet\\pipeline.config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Tensorboard to see the losses in the model\n",
    "# Navigate to Tensorflow/workspace and run the following command in cmd\n",
    "\n",
    "tensorboard --logdir=models/my_ssd_mobnet\n",
    "\n",
    "\n",
    "# Once you receive a url for the port(ex, http://localhost:6006/), paste it in browser to see the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912f3bd",
   "metadata": {},
   "source": [
    "## 6. Load model from auto saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36750e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_path)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Restore checkpoint from the latest check point 3(Always use the last checkpoint)\n",
    "checkpoint_path = os.path.join('Tensorflow','workspace','models', 'my_ssd_mobnet')\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(checkpoint_path, 'ckpt-3')).expect_partial()\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf666ad",
   "metadata": {},
   "source": [
    "## 7. Object Detection from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255300a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e76db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap_path = os.path.join('Tensorflow', 'workspace','annotations','label_map.pbtxt')\n",
    "category_index = label_map_util.create_category_index_from_labelmap(label_map_path=labelmap_path)\n",
    "IMAGE_PATH = os.path.join('Tensorflow', 'workspace','images','test',\n",
    "                          'ok.9533399a-6d8e-11ec-a41a-98fa9b97e1dd.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e024eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c3091",
   "metadata": {},
   "source": [
    "## 8. Detect from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    \n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
